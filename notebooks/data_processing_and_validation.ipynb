{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76f5073f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/jupyterlab/3.3.2/libexec/bin/python3.9\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f49c52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/ngoutzoulias/Library/Python/3.9/lib/python/site-packages (from -r ../requirements.txt (line 1)) (1.26.3)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from -r ../requirements.txt (line 2)) (2.1.4)\n",
      "Collecting seaborn (from -r ../requirements.txt (line 3))\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting matplotlib (from -r ../requirements.txt (line 4))\n",
      "  Downloading matplotlib-3.9.3-cp39-cp39-macosx_10_12_x86_64.whl.metadata (11 kB)\n",
      "Collecting nltk (from -r ../requirements.txt (line 5))\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: scikit-learn in /Users/ngoutzoulias/Library/Python/3.9/lib/python/site-packages (from -r ../requirements.txt (line 6)) (1.4.0)\n",
      "Collecting wordcloud (from -r ../requirements.txt (line 7))\n",
      "  Downloading wordcloud-1.9.4-cp39-cp39-macosx_10_9_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting bs4 (from -r ../requirements.txt (line 8))\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Collecting spacy (from -r ../requirements.txt (line 9))\n",
      "  Downloading spacy-3.8.2-cp39-cp39-macosx_10_9_x86_64.whl.metadata (27 kB)\n",
      "Collecting textblob (from -r ../requirements.txt (line 10))\n",
      "  Downloading textblob-0.18.0.post0-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pandas->-r ../requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pandas->-r ../requirements.txt (line 2)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pandas->-r ../requirements.txt (line 2)) (2023.4)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->-r ../requirements.txt (line 4))\n",
      "  Downloading contourpy-1.3.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->-r ../requirements.txt (line 4))\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->-r ../requirements.txt (line 4))\n",
      "  Downloading fonttools-4.55.2-cp39-cp39-macosx_10_9_x86_64.whl.metadata (164 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->-r ../requirements.txt (line 4))\n",
      "  Downloading kiwisolver-1.4.7-cp39-cp39-macosx_10_9_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib->-r ../requirements.txt (line 4)) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from matplotlib->-r ../requirements.txt (line 4)) (11.0.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib->-r ../requirements.txt (line 4))\n",
      "  Downloading pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting importlib-resources>=3.2.0 (from matplotlib->-r ../requirements.txt (line 4))\n",
      "  Downloading importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting click (from nltk->-r ../requirements.txt (line 5))\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: joblib in /Users/ngoutzoulias/Library/Python/3.9/lib/python/site-packages (from nltk->-r ../requirements.txt (line 5)) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from nltk->-r ../requirements.txt (line 5)) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from nltk->-r ../requirements.txt (line 5)) (4.67.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/ngoutzoulias/Library/Python/3.9/lib/python/site-packages (from scikit-learn->-r ../requirements.txt (line 6)) (1.12.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/ngoutzoulias/Library/Python/3.9/lib/python/site-packages (from scikit-learn->-r ../requirements.txt (line 6)) (3.2.0)\n",
      "Collecting beautifulsoup4 (from bs4->-r ../requirements.txt (line 8))\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy->-r ../requirements.txt (line 9))\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy->-r ../requirements.txt (line 9))\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy->-r ../requirements.txt (line 9))\n",
      "  Downloading murmurhash-1.0.11-cp39-cp39-macosx_10_9_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy->-r ../requirements.txt (line 9))\n",
      "  Downloading cymem-2.0.10-cp39-cp39-macosx_10_9_x86_64.whl.metadata (8.4 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy->-r ../requirements.txt (line 9))\n",
      "  Downloading preshed-3.0.9-cp39-cp39-macosx_10_9_x86_64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.0 (from spacy->-r ../requirements.txt (line 9))\n",
      "  Downloading thinc-8.3.2-cp39-cp39-macosx_10_9_x86_64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy->-r ../requirements.txt (line 9))\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy->-r ../requirements.txt (line 9))\n",
      "  Downloading srsly-2.4.8-cp39-cp39-macosx_10_9_x86_64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy->-r ../requirements.txt (line 9))\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy->-r ../requirements.txt (line 9))\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy->-r ../requirements.txt (line 9))\n",
      "  Downloading typer-0.15.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy->-r ../requirements.txt (line 9)) (2.32.3)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy->-r ../requirements.txt (line 9))\n",
      "  Downloading pydantic-2.10.3-py3-none-any.whl.metadata (172 kB)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy->-r ../requirements.txt (line 9)) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from spacy->-r ../requirements.txt (line 9)) (58.1.0)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy->-r ../requirements.txt (line 9))\n",
      "  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting zipp>=3.1.0 (from importlib-resources>=3.2.0->matplotlib->-r ../requirements.txt (line 4))\n",
      "  Downloading zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy->-r ../requirements.txt (line 9))\n",
      "  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r ../requirements.txt (line 9))\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.1 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r ../requirements.txt (line 9))\n",
      "  Downloading pydantic_core-2.27.1-cp39-cp39-macosx_10_12_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r ../requirements.txt (line 9)) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->-r ../requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy->-r ../requirements.txt (line 9)) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy->-r ../requirements.txt (line 9)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy->-r ../requirements.txt (line 9)) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy->-r ../requirements.txt (line 9)) (2024.8.30)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting blis<1.1.0,>=1.0.0 (from thinc<8.4.0,>=8.3.0->spacy->-r ../requirements.txt (line 9))\n",
      "  Downloading blis-1.0.1-cp39-cp39-macosx_10_9_x86_64.whl.metadata (7.6 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.0->spacy->-r ../requirements.txt (line 9))\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "INFO: pip is looking at multiple versions of thinc to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting thinc<8.4.0,>=8.3.0 (from spacy->-r ../requirements.txt (line 9))\n",
      "  Downloading thinc-8.3.1-cp39-cp39-macosx_10_9_x86_64.whl.metadata (15 kB)\n",
      "  Downloading thinc-8.3.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata (15 kB)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn->-r ../requirements.txt (line 6))\n",
      "  Downloading scipy-1.13.1-cp39-cp39-macosx_10_9_x86_64.whl.metadata (60 kB)\n",
      "  Downloading scipy-1.13.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata (60 kB)\n",
      "INFO: pip is still looking at multiple versions of thinc to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading scipy-1.12.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata (60 kB)\n",
      "  Downloading scipy-1.11.4-cp39-cp39-macosx_10_9_x86_64.whl.metadata (60 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading scipy-1.11.3-cp39-cp39-macosx_10_9_x86_64.whl.metadata (60 kB)\n",
      "  Downloading scipy-1.11.2-cp39-cp39-macosx_10_9_x86_64.whl.metadata (54 kB)\n",
      "  Downloading scipy-1.11.1-cp39-cp39-macosx_10_9_x86_64.whl.metadata (54 kB)\n",
      "  Downloading scipy-1.10.1-cp39-cp39-macosx_10_9_x86_64.whl.metadata (53 kB)\n",
      "  Downloading scipy-1.10.0-cp39-cp39-macosx_10_15_x86_64.whl.metadata (53 kB)\n",
      "  Downloading scipy-1.9.3-cp39-cp39-macosx_10_9_x86_64.whl.metadata (53 kB)\n",
      "Collecting numpy (from -r ../requirements.txt (line 1))\n",
      "  Downloading numpy-1.25.2-cp39-cp39-macosx_10_9_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn->-r ../requirements.txt (line 6))\n",
      "  Downloading scipy-1.9.2-cp39-cp39-macosx_10_9_x86_64.whl.metadata (53 kB)\n",
      "  Downloading scipy-1.9.1-cp39-cp39-macosx_12_0_universal2.macosx_10_9_x86_64.whl.metadata (2.2 kB)\n",
      "Collecting numpy (from -r ../requirements.txt (line 1))\n",
      "  Downloading numpy-1.24.4-cp39-cp39-macosx_10_9_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn->-r ../requirements.txt (line 6))\n",
      "  Downloading scipy-1.9.0-cp39-cp39-macosx_12_0_universal2.macosx_10_9_x86_64.whl.metadata (2.2 kB)\n",
      "  Downloading scipy-1.8.1-cp39-cp39-macosx_12_0_universal2.macosx_10_9_x86_64.whl.metadata (2.2 kB)\n",
      "  Downloading scipy-1.8.0-cp39-cp39-macosx_12_0_universal2.macosx_10_9_x86_64.whl.metadata (2.2 kB)\n",
      "  Downloading scipy-1.7.3-cp39-cp39-macosx_10_9_x86_64.whl.metadata (2.2 kB)\n",
      "INFO: pip is looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading scipy-1.7.2-cp39-cp39-macosx_10_9_x86_64.whl.metadata (2.2 kB)\n",
      "  Downloading scipy-1.7.1-cp39-cp39-macosx_10_9_x86_64.whl.metadata (2.2 kB)\n",
      "  Downloading scipy-1.7.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata (2.2 kB)\n",
      "  Downloading scipy-1.6.3-cp39-cp39-macosx_10_9_x86_64.whl.metadata (2.1 kB)\n",
      "  Downloading scipy-1.6.2-cp39-cp39-macosx_10_9_x86_64.whl.metadata (2.1 kB)\n",
      "  Downloading scipy-1.6.1-cp39-cp39-macosx_10_9_x86_64.whl.metadata (2.0 kB)\n",
      "INFO: pip is still looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading scipy-1.6.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata (2.0 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->-r ../requirements.txt (line 4))\n",
      "  Downloading contourpy-1.2.1-cp39-cp39-macosx_10_9_x86_64.whl.metadata (5.8 kB)\n",
      "  Downloading contourpy-1.2.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata (5.8 kB)\n",
      "  Downloading contourpy-1.1.1-cp39-cp39-macosx_10_9_x86_64.whl.metadata (5.9 kB)\n",
      "  Downloading contourpy-1.1.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata (5.7 kB)\n",
      "  Downloading contourpy-1.0.7-cp39-cp39-macosx_10_9_x86_64.whl.metadata (3.8 kB)\n",
      "  Downloading contourpy-1.0.6-cp39-cp39-macosx_10_9_x86_64.whl.metadata (3.5 kB)\n",
      "  Downloading contourpy-1.0.5-cp39-cp39-macosx_10_9_x86_64.whl.metadata (3.3 kB)\n",
      "  Downloading contourpy-1.0.4-cp39-cp39-macosx_10_9_x86_64.whl.metadata (3.2 kB)\n",
      "  Downloading contourpy-1.0.3-cp39-cp39-macosx_10_9_x86_64.whl.metadata (3.0 kB)\n",
      "  Downloading contourpy-1.0.2-cp39-cp39-macosx_10_9_x86_64.whl.metadata (2.2 kB)\n",
      "  Downloading contourpy-1.0.1-cp39-cp39-macosx_10_9_x86_64.whl.metadata (2.2 kB)\n",
      "Collecting spacy (from -r ../requirements.txt (line 9))\n",
      "  Downloading spacy-3.7.5-cp39-cp39-macosx_10_9_x86_64.whl.metadata (27 kB)\n",
      "Collecting thinc<8.3.0,>=8.2.2 (from spacy->-r ../requirements.txt (line 9))\n",
      "  Downloading thinc-8.2.5-cp39-cp39-macosx_10_9_x86_64.whl.metadata (15 kB)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.2.2->spacy->-r ../requirements.txt (line 9))\n",
      "  Downloading blis-0.7.11-cp39-cp39-macosx_10_9_x86_64.whl.metadata (7.4 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy->-r ../requirements.txt (line 9))\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0.0,>=0.3.0->spacy->-r ../requirements.txt (line 9))\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy->-r ../requirements.txt (line 9))\n",
      "  Downloading cloudpathlib-0.20.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy->-r ../requirements.txt (line 9))\n",
      "  Downloading smart_open-7.0.5-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->bs4->-r ../requirements.txt (line 8))\n",
      "  Using cached soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from jinja2->spacy->-r ../requirements.txt (line 9)) (3.0.2)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->-r ../requirements.txt (line 9))\n",
      "  Downloading marisa_trie-1.2.1-cp39-cp39-macosx_10_9_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->-r ../requirements.txt (line 9))\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting pygments<3.0.0,>=2.13.0 (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->-r ../requirements.txt (line 9))\n",
      "  Using cached pygments-2.18.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting wrapt (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->-r ../requirements.txt (line 9))\n",
      "  Downloading wrapt-1.17.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->-r ../requirements.txt (line 9))\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading matplotlib-3.9.3-cp39-cp39-macosx_10_12_x86_64.whl (7.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wordcloud-1.9.4-cp39-cp39-macosx_10_9_x86_64.whl (172 kB)\n",
      "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Downloading spacy-3.7.5-cp39-cp39-macosx_10_9_x86_64.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.0-cp39-cp39-macosx_10_9_x86_64.whl (265 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading textblob-0.18.0.post0-py3-none-any.whl (626 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m626.3/626.3 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading cymem-2.0.10-cp39-cp39-macosx_10_9_x86_64.whl (42 kB)\n",
      "Downloading fonttools-4.55.2-cp39-cp39-macosx_10_9_x86_64.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "Downloading kiwisolver-1.4.7-cp39-cp39-macosx_10_9_x86_64.whl (65 kB)\n",
      "Downloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Downloading murmurhash-1.0.11-cp39-cp39-macosx_10_9_x86_64.whl (26 kB)\n",
      "Downloading preshed-3.0.9-cp39-cp39-macosx_10_9_x86_64.whl (133 kB)\n",
      "Downloading pydantic-2.10.3-py3-none-any.whl (456 kB)\n",
      "Downloading pydantic_core-2.27.1-cp39-cp39-macosx_10_12_x86_64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.4.8-cp39-cp39-macosx_10_9_x86_64.whl (493 kB)\n",
      "Downloading thinc-8.2.5-cp39-cp39-macosx_10_9_x86_64.whl (847 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m847.9/847.9 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.15.1-py3-none-any.whl (44 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading blis-0.7.11-cp39-cp39-macosx_10_9_x86_64.whl (6.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cloudpathlib-0.20.0-py3-none-any.whl (52 kB)\n",
      "Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading smart_open-7.0.5-py3-none-any.whl (61 kB)\n",
      "Using cached soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Downloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Downloading marisa_trie-1.2.1-cp39-cp39-macosx_10_9_x86_64.whl (192 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
      "Downloading wrapt-1.17.0-py3-none-any.whl (23 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: cymem, zipp, wrapt, wasabi, spacy-loggers, spacy-legacy, soupsieve, shellingham, pyparsing, pygments, pydantic-core, murmurhash, mdurl, marisa-trie, kiwisolver, fonttools, cycler, contourpy, cloudpathlib, click, catalogue, blis, annotated-types, srsly, smart-open, pydantic, preshed, nltk, markdown-it-py, language-data, importlib-resources, beautifulsoup4, textblob, rich, matplotlib, langcodes, confection, bs4, wordcloud, typer, thinc, seaborn, weasel, spacy\n",
      "Successfully installed annotated-types-0.7.0 beautifulsoup4-4.12.3 blis-0.7.11 bs4-0.0.2 catalogue-2.0.10 click-8.1.7 cloudpathlib-0.20.0 confection-0.1.5 contourpy-1.3.0 cycler-0.12.1 cymem-2.0.10 fonttools-4.55.2 importlib-resources-6.4.5 kiwisolver-1.4.7 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 markdown-it-py-3.0.0 matplotlib-3.9.3 mdurl-0.1.2 murmurhash-1.0.11 nltk-3.9.1 preshed-3.0.9 pydantic-2.10.3 pydantic-core-2.27.1 pygments-2.18.0 pyparsing-3.2.0 rich-13.9.4 seaborn-0.13.2 shellingham-1.5.4 smart-open-7.0.5 soupsieve-2.6 spacy-3.7.5 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 textblob-0.18.0.post0 thinc-8.2.5 typer-0.15.1 wasabi-1.1.3 weasel-0.4.1 wordcloud-1.9.4 wrapt-1.17.0 zipp-3.21.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85dde506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /Users/ngoutzoulias/Library/Python/3.9/lib/python/site-packages (from pandas) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c84f46f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Load the libraries\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "#Load the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy\n",
    "import re,string,unicodedata\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.stem import LancasterStemmer,WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f816e25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = '../datasets/imdb_dataset.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186eb3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d54b3855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Loved today's show!!! It was a variety and not...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "count                                               50000     50000\n",
       "unique                                              49582         2\n",
       "top     Loved today's show!!! It was a variety and not...  positive\n",
       "freq                                                    5     25000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Summary of the dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c502efad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    25000\n",
       "negative    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sentiment count\n",
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b51ba4e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ToktokTokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kn/mg0q954144g1v7cpg2yb2zj40000gn/T/ipykernel_89824/1515494159.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Tokenization of text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mToktokTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#Setting English stopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstopword_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ToktokTokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "#Tokenization of text\n",
    "tokenizer=ToktokTokenizer()\n",
    "#Setting English stopwords\n",
    "stopword_list=nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ab7ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the html strips\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "#Removing the square brackets\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "\n",
    "#Removing the noisy text\n",
    "def denoise_text(text):\n",
    "    text = strip_html(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    return text\n",
    "#Apply function on review column\n",
    "df['review']=df['review'].apply(denoise_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e654c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function for removing special characters\n",
    "def remove_special_characters(text, remove_digits=True):\n",
    "    pattern=r'[^a-zA-z0-9\\s]'\n",
    "    text=re.sub(pattern,'',text)\n",
    "    return text\n",
    "#Apply function on review column\n",
    "df['review']=df['review'].apply(remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab57d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming the text\n",
    "def simple_stemmer(text):\n",
    "    ps=nltk.porter.PorterStemmer()\n",
    "    text= ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return text\n",
    "#Apply function on review column\n",
    "imdb_data['review']=imdb_data['review'].apply(simple_stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51d864f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set stopwords to english\n",
    "stop=set(stopwords.words('english'))\n",
    "print(stop)\n",
    "\n",
    "#removing the stopwords\n",
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "#Apply function on review column\n",
    "imdb_data['review']=imdb_data['review'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e91522",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalized train reviews\n",
    "norm_reviews=df.review\n",
    "norm_reviews[0]\n",
    "#convert dataframe to string\n",
    "#norm_train_string=norm_train_reviews.to_string()\n",
    "#Spelling correction using Textblob\n",
    "#norm_train_spelling=TextBlob(norm_train_string)\n",
    "#norm_train_spelling.correct()\n",
    "#Tokenization using Textblob\n",
    "#norm_train_words=norm_train_spelling.words\n",
    "#norm_train_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a68701",
   "metadata": {},
   "outputs": [],
   "source": [
    "#labeling the sentient data\n",
    "lb=LabelBinarizer()\n",
    "#transformed sentiment data\n",
    "sentiment_data=lb.fit_transform(df['sentiment'])\n",
    "print(sentiment_data.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
